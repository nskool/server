{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d13fb4e9",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Run Multiple Models on the Same GPU with Amazon SageMaker Multi-Model Endpoints Powered by NVIDIA Triton Inference Server\n",
    "\n",
    "This notebook was run on a `ml.g4dn.xlarge` SageMaker Notebook instance type, with `conda_pytorch_p38` kernel.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "Install the necessary Python modules to use and interact with [NVIDIA Triton Inference Server](https://github.com/triton-inference-server/server/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a41dedb0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com, https://pypi.ngc.nvidia.com\n",
      "Collecting torch==1.10.0\n",
      "  Downloading torch-1.10.0-cp38-cp38-manylinux1_x86_64.whl (881.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m881.9/881.9 MB\u001b[0m \u001b[31m294.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: sagemaker in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (2.132.0)\n",
      "Collecting transformers==4.9.1\n",
      "  Downloading transformers-4.9.1-py3-none-any.whl (2.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m341.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tritonclient[all] in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (2.27.0)\n",
      "Requirement already satisfied: typing-extensions in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from torch==1.10.0) (4.0.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from transformers==4.9.1) (2021.11.10)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from transformers==4.9.1) (3.4.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from transformers==4.9.1) (5.4.1)\n",
      "Collecting sacremoses\n",
      "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m880.6/880.6 kB\u001b[0m \u001b[31m343.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting tokenizers<0.11,>=0.10.1\n",
      "  Downloading tokenizers-0.10.3-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m338.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from transformers==4.9.1) (20.9)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from transformers==4.9.1) (1.20.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from transformers==4.9.1) (4.62.3)\n",
      "Collecting huggingface-hub==0.0.12\n",
      "  Downloading huggingface_hub-0.0.12-py3-none-any.whl (37 kB)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from transformers==4.9.1) (2.26.0)\n",
      "Requirement already satisfied: attrs<23,>=20.3.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from sagemaker) (21.2.0)\n",
      "Requirement already satisfied: importlib-metadata<5.0,>=1.4.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from sagemaker) (4.8.2)\n",
      "Requirement already satisfied: schema in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from sagemaker) (0.7.5)\n",
      "Requirement already satisfied: google-pasta in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from sagemaker) (0.2.0)\n",
      "Requirement already satisfied: pandas in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from sagemaker) (1.4.2)\n",
      "Requirement already satisfied: pathos in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from sagemaker) (0.2.8)\n",
      "Requirement already satisfied: boto3<2.0,>=1.26.28 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from sagemaker) (1.26.73)\n",
      "Requirement already satisfied: protobuf<4.0,>=3.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from sagemaker) (3.19.1)\n",
      "Requirement already satisfied: protobuf3-to-dict<1.0,>=0.1.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from sagemaker) (0.1.5)\n",
      "Requirement already satisfied: smdebug-rulesconfig==1.0.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from sagemaker) (1.0.1)\n",
      "Requirement already satisfied: python-rapidjson>=0.9.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from tritonclient[all]) (1.9)\n",
      "Collecting grpcio==1.41.0\n",
      "  Downloading grpcio-1.41.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.9/3.9 MB\u001b[0m \u001b[31m138.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: aiohttp>=3.8.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from tritonclient[all]) (3.8.1)\n",
      "Requirement already satisfied: geventhttpclient<=2.0.2,>=1.4.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from tritonclient[all]) (2.0.2)\n",
      "Requirement already satisfied: six>=1.5.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from grpcio==1.41.0->tritonclient[all]) (1.16.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from aiohttp>=3.8.1->tritonclient[all]) (5.2.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from aiohttp>=3.8.1->tritonclient[all]) (4.0.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from aiohttp>=3.8.1->tritonclient[all]) (1.2.0)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from aiohttp>=3.8.1->tritonclient[all]) (2.0.8)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from aiohttp>=3.8.1->tritonclient[all]) (1.7.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from aiohttp>=3.8.1->tritonclient[all]) (1.2.0)\n",
      "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from boto3<2.0,>=1.26.28->sagemaker) (0.6.0)\n",
      "Requirement already satisfied: botocore<1.30.0,>=1.29.73 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from boto3<2.0,>=1.26.28->sagemaker) (1.29.73)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from boto3<2.0,>=1.26.28->sagemaker) (0.10.0)\n",
      "Requirement already satisfied: gevent>=0.13 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from geventhttpclient<=2.0.2,>=1.4.4->tritonclient[all]) (21.8.0)\n",
      "Requirement already satisfied: brotli in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from geventhttpclient<=2.0.2,>=1.4.4->tritonclient[all]) (1.0.9)\n",
      "Requirement already satisfied: certifi in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from geventhttpclient<=2.0.2,>=1.4.4->tritonclient[all]) (2022.12.7)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from importlib-metadata<5.0,>=1.4.0->sagemaker) (3.6.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from packaging->transformers==4.9.1) (3.0.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from pandas->sagemaker) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from pandas->sagemaker) (2021.3)\n",
      "Requirement already satisfied: pox>=0.3.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from pathos->sagemaker) (0.3.0)\n",
      "Requirement already satisfied: ppft>=1.6.6.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from pathos->sagemaker) (1.6.6.4)\n",
      "Requirement already satisfied: dill>=0.3.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from pathos->sagemaker) (0.3.4)\n",
      "Requirement already satisfied: multiprocess>=0.70.12 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from pathos->sagemaker) (0.70.12.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from requests->transformers==4.9.1) (1.26.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from requests->transformers==4.9.1) (3.1)\n",
      "Requirement already satisfied: click in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from sacremoses->transformers==4.9.1) (8.0.3)\n",
      "Requirement already satisfied: joblib in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from sacremoses->transformers==4.9.1) (1.1.0)\n",
      "Requirement already satisfied: contextlib2>=0.5.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from schema->sagemaker) (21.6.0)\n",
      "Requirement already satisfied: greenlet<2.0,>=1.1.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from gevent>=0.13->geventhttpclient<=2.0.2,>=1.4.4->tritonclient[all]) (1.1.2)\n",
      "Requirement already satisfied: zope.interface in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from gevent>=0.13->geventhttpclient<=2.0.2,>=1.4.4->tritonclient[all]) (5.4.0)\n",
      "Requirement already satisfied: zope.event in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from gevent>=0.13->geventhttpclient<=2.0.2,>=1.4.4->tritonclient[all]) (4.5.0)\n",
      "Requirement already satisfied: setuptools in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from gevent>=0.13->geventhttpclient<=2.0.2,>=1.4.4->tritonclient[all]) (59.4.0)\n",
      "Building wheels for collected packages: sacremoses\n",
      "  Building wheel for sacremoses (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895260 sha256=c3ac8e117e7a6eee4d695c47d4627c8457b020826d621b286db1c711ee7fc9b4\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-bntn7mbe/wheels/82/ab/9b/c15899bf659ba74f623ac776e861cf2eb8608c1825ddec66a4\n",
      "Successfully built sacremoses\n",
      "Installing collected packages: tokenizers, torch, sacremoses, grpcio, huggingface-hub, transformers\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.12.1\n",
      "    Uninstalling tokenizers-0.12.1:\n",
      "      Successfully uninstalled tokenizers-0.12.1\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 1.12.1+cu113\n",
      "    Uninstalling torch-1.12.1+cu113:\n",
      "      Successfully uninstalled torch-1.12.1+cu113\n",
      "  Attempting uninstall: huggingface-hub\n",
      "    Found existing installation: huggingface-hub 0.8.1\n",
      "    Uninstalling huggingface-hub-0.8.1:\n",
      "      Successfully uninstalled huggingface-hub-0.8.1\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.20.1\n",
      "    Uninstalling transformers-4.20.1:\n",
      "      Successfully uninstalled transformers-4.20.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchvision 0.13.1+cu113 requires torch==1.12.1, but you have torch 1.10.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed grpcio-1.41.0 huggingface-hub-0.0.12 sacremoses-0.0.53 tokenizers-0.10.3 torch-1.10.0 transformers-4.9.1\n"
     ]
    }
   ],
   "source": [
    "! pip install torch==1.10.0 sagemaker transformers==4.9.1 tritonclient[all]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d65e53",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Part 1 - Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7a3cc38",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import boto3\n",
    "import copy\n",
    "import datetime\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pprint\n",
    "import re\n",
    "import sagemaker\n",
    "import sys\n",
    "import time\n",
    "from time import gmtime, strftime\n",
    "import tritonclient.http as http_client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "239766ef",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "session = boto3.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "sm_client = session.client(\"sagemaker\")\n",
    "sagemaker_session = sagemaker.Session(boto_session=session)\n",
    "sm_runtime_client = boto3.client(\"sagemaker-runtime\")\n",
    "\n",
    "region = boto3.Session().region_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f15bf1a",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "account_id_map = {\n",
    "    \"us-east-1\": \"785573368785\",\n",
    "    \"us-east-2\": \"007439368137\",\n",
    "    \"us-west-1\": \"710691900526\",\n",
    "    \"us-west-2\": \"301217895009\",\n",
    "    \"eu-west-1\": \"802834080501\",\n",
    "    \"eu-west-2\": \"205493899709\",\n",
    "    \"eu-west-3\": \"254080097072\",\n",
    "    \"eu-north-1\": \"601324751636\",\n",
    "    \"eu-south-1\": \"966458181534\",\n",
    "    \"eu-central-1\": \"746233611703\",\n",
    "    \"ap-east-1\": \"110948597952\",\n",
    "    \"ap-south-1\": \"763008648453\",\n",
    "    \"ap-northeast-1\": \"941853720454\",\n",
    "    \"ap-northeast-2\": \"151534178276\",\n",
    "    \"ap-southeast-1\": \"324986816169\",\n",
    "    \"ap-southeast-2\": \"355873309152\",\n",
    "    \"cn-northwest-1\": \"474822919863\",\n",
    "    \"cn-north-1\": \"472730292857\",\n",
    "    \"sa-east-1\": \"756306329178\",\n",
    "    \"ca-central-1\": \"464438896020\",\n",
    "    \"me-south-1\": \"836785723513\",\n",
    "    \"af-south-1\": \"774647643957\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2321e3a0",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df688118",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Part 2 - Save Model and tokenizer\n",
    "\n",
    "We now save the tokenizer and the model to folders within the model repository\n",
    "\n",
    "### Parameters:\n",
    "\n",
    "* `model_name`: Model identifier from the Hugging Face model hub library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3473675",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d7ac539d9ed4d699e2155229d3edc12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/482 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3078be5bd88a46e981a21337900b38bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a725443d6fd84fc1b4924958fa311de0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f489e96be80048199a2dd52f4374b132",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16c031d88d6f4d0398ec958894723058",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.43G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model_id = \"roberta-large\"\n",
    "from transformers import AutoTokenizer,AutoModel\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModel.from_pretrained(model_id)\n",
    "tokenizer.save_pretrained('model_repo/e2e/tokenizer')\n",
    "model.save_pretrained('model_repo/e2e/model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c84d278",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Part 3 - Run Local Triton Inference Server"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "514bf74e",
   "metadata": {},
   "source": [
    "> **WARNING**: The cells under part 3 will only work if run within a SageMaker Notebook Instance!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b14777",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "\n",
    "\n",
    "The following cells run the Triton Inference Server container in the background and load all the models within the folder `/model_repo`. The docker won't fail if one or more of the model fails because of `--exit-on-error=false`, which is useful for iterative code and model repository building. Remove `-d` to see the logs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f816469d",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted Networks:\n",
      "sagemaker-local\n",
      "\n",
      "Total reclaimed space: 0B\n"
     ]
    }
   ],
   "source": [
    "!sudo docker system prune -f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "abf8e593",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to find image 'nvcr.io/nvidia/tritonserver:22.12-py3' locally\n",
      "22.12-py3: Pulling from nvidia/tritonserver\n",
      "\n",
      "\u001b[1B0b181fff: Pulling fs layer \n",
      "\u001b[1Bf751e984: Pulling fs layer \n",
      "\u001b[1Bb807c637: Pulling fs layer \n",
      "\u001b[1B2991e393: Pulling fs layer \n",
      "\u001b[1B71274096: Pulling fs layer \n",
      "\u001b[1B91138ef8: Pulling fs layer \n",
      "\u001b[1Bed3c7117: Pulling fs layer \n",
      "\u001b[1B46181ee6: Pulling fs layer \n",
      "\u001b[1Ba7918caa: Pulling fs layer \n",
      "\u001b[1B2fbe7c33: Pulling fs layer \n",
      "\u001b[1B8dd49356: Pulling fs layer \n",
      "\u001b[1B8fc97997: Pulling fs layer \n",
      "\u001b[1Ba4765a47: Pulling fs layer \n",
      "\u001b[1Bb700ef54: Pulling fs layer \n",
      "\u001b[1B42d4d1d7: Pulling fs layer \n",
      "\u001b[1Bb7b91111: Pulling fs layer \n",
      "\u001b[1B57c41539: Pulling fs layer \n",
      "\u001b[1Bbf837893: Pulling fs layer \n",
      "\u001b[1Bcb208312: Pulling fs layer \n",
      "\u001b[1B3fcdfbd9: Pulling fs layer \n",
      "\u001b[1B2037b0cf: Pulling fs layer \n",
      "\u001b[1Be9aef86f: Pulling fs layer \n",
      "\u001b[1Bf2adb71b: Pulling fs layer \n",
      "\u001b[1Bba395cd0: Pull complete 137kB/2.137kBB\u001b[24A\u001b[2K\u001b[24A\u001b[2K\u001b[24A\u001b[2K\u001b[23A\u001b[2K\u001b[22A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[22A\u001b[2K\u001b[22A\u001b[2K\u001b[20A\u001b[2K\u001b[24A\u001b[2K\u001b[24A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[17A\u001b[2K\u001b[23A\u001b[2K\u001b[20A\u001b[2K\u001b[23A\u001b[2K\u001b[20A\u001b[2K\u001b[23A\u001b[2K\u001b[20A\u001b[2K\u001b[23A\u001b[2K\u001b[14A\u001b[2K\u001b[15A\u001b[2K\u001b[14A\u001b[2K\u001b[23A\u001b[2K\u001b[14A\u001b[2K\u001b[23A\u001b[2K\u001b[14A\u001b[2K\u001b[23A\u001b[2K\u001b[14A\u001b[2K\u001b[23A\u001b[2K\u001b[14A\u001b[2K\u001b[14A\u001b[2K\u001b[23A\u001b[2K\u001b[12A\u001b[2K\u001b[23A\u001b[2K\u001b[12A\u001b[2K\u001b[23A\u001b[2K\u001b[11A\u001b[2K\u001b[20A\u001b[2K\u001b[12A\u001b[2K\u001b[20A\u001b[2K\u001b[12A\u001b[2K\u001b[20A\u001b[2K\u001b[12A\u001b[2K\u001b[20A\u001b[2K\u001b[12A\u001b[2K\u001b[20A\u001b[2K\u001b[23A\u001b[2K\u001b[20A\u001b[2K\u001b[23A\u001b[2K\u001b[20A\u001b[2K\u001b[23A\u001b[2K\u001b[20A\u001b[2K\u001b[9A\u001b[2K\u001b[20A\u001b[2K\u001b[23A\u001b[2K\u001b[20A\u001b[2K\u001b[23A\u001b[2K\u001b[20A\u001b[2K\u001b[12A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[20A\u001b[2K\u001b[12A\u001b[2K\u001b[20A\u001b[2K\u001b[12A\u001b[2K\u001b[20A\u001b[2K\u001b[12A\u001b[2K\u001b[20A\u001b[2K\u001b[12A\u001b[2K\u001b[20A\u001b[2K\u001b[12A\u001b[2K\u001b[20A\u001b[2K\u001b[22A\u001b[2K\u001b[20A\u001b[2K\u001b[22A\u001b[2K\u001b[20A\u001b[2K\u001b[22A\u001b[2K\u001b[20A\u001b[2K\u001b[22A\u001b[2K\u001b[20A\u001b[2K\u001b[22A\u001b[2K\u001b[20A\u001b[2K\u001b[12A\u001b[2K\u001b[20A\u001b[2K\u001b[12A\u001b[2K\u001b[20A\u001b[2K\u001b[8A\u001b[2K\u001b[20A\u001b[2K\u001b[12A\u001b[2K\u001b[22A\u001b[2K\u001b[12A\u001b[2K\u001b[22A\u001b[2K\u001b[22A\u001b[2K\u001b[20A\u001b[2K\u001b[5A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[4A\u001b[2K\u001b[20A\u001b[2K\u001b[6A\u001b[2K\u001b[20A\u001b[2K\u001b[22A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[22A\u001b[2K\u001b[22A\u001b[2K\u001b[22A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[3A\u001b[2K\u001b[20A\u001b[2K\u001b[3A\u001b[2K\u001b[20A\u001b[2K\u001b[3A\u001b[2K\u001b[20A\u001b[2K\u001b[3A\u001b[2K\u001b[20A\u001b[2K\u001b[3A\u001b[2K\u001b[20A\u001b[2K\u001b[3A\u001b[2K\u001b[20A\u001b[2K\u001b[3A\u001b[2K\u001b[20A\u001b[2K\u001b[3A\u001b[2K\u001b[20A\u001b[2K\u001b[3A\u001b[2K\u001b[20A\u001b[2K\u001b[3A\u001b[2K\u001b[20A\u001b[2K\u001b[3A\u001b[2K\u001b[20A\u001b[2K\u001b[3A\u001b[2K\u001b[20A\u001b[2K\u001b[3A\u001b[2K\u001b[20A\u001b[2K\u001b[3A\u001b[2K\u001b[20A\u001b[2K\u001b[3A\u001b[2K\u001b[20A\u001b[2K\u001b[3A\u001b[2K\u001b[20A\u001b[2K\u001b[3A\u001b[2K\u001b[20A\u001b[2K\u001b[3A\u001b[2K\u001b[20A\u001b[2K\u001b[3A\u001b[2K\u001b[20A\u001b[2K\u001b[3A\u001b[2K\u001b[20A\u001b[2K\u001b[3A\u001b[2K\u001b[20A\u001b[2K\u001b[3A\u001b[2K\u001b[20A\u001b[2K\u001b[3A\u001b[2K\u001b[20A\u001b[2K\u001b[3A\u001b[2K\u001b[20A\u001b[2K\u001b[3A\u001b[2K\u001b[20A\u001b[2K\u001b[3A\u001b[2K\u001b[20A\u001b[2K\u001b[3A\u001b[2K\u001b[20A\u001b[2K\u001b[3A\u001b[2K\u001b[20A\u001b[2K\u001b[3A\u001b[2K\u001b[20A\u001b[2K\u001b[3A\u001b[2K\u001b[20A\u001b[2K\u001b[3A\u001b[2K\u001b[20A\u001b[2K\u001b[3A\u001b[2K\u001b[20A\u001b[2K\u001b[3A\u001b[2K\u001b[20A\u001b[2K\u001b[3A\u001b[2K\u001b[20A\u001b[2K\u001b[3A\u001b[2K\u001b[20A\u001b[2K\u001b[3A\u001b[2K\u001b[20A\u001b[2K\u001b[3A\u001b[2K\u001b[20A\u001b[2K\u001b[3A\u001b[2K\u001b[20A\u001b[2K\u001b[3A\u001b[2K\u001b[20A\u001b[2K\u001b[3A\u001b[2K\u001b[20A\u001b[2K\u001b[3A\u001b[2K\u001b[20A\u001b[2K\u001b[3A\u001b[2K\u001b[20A\u001b[2K\u001b[3A\u001b[2K\u001b[20A\u001b[2K\u001b[3A\u001b[2K\u001b[20A\u001b[2K\u001b[3A\u001b[2K\u001b[20A\u001b[2K\u001b[3A\u001b[2K\u001b[20A\u001b[2K\u001b[3A\u001b[2K\u001b[20A\u001b[2K\u001b[3A\u001b[2K\u001b[20A\u001b[2K\u001b[3A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[20A\u001b[2K\u001b[3A\u001b[2K\u001b[20A\u001b[2K\u001b[3A\u001b[2K\u001b[20A\u001b[2K\u001b[3A\u001b[2K\u001b[20A\u001b[2K\u001b[3A\u001b[2K\u001b[20A\u001b[2K\u001b[3A\u001b[2K\u001b[20A\u001b[2K\u001b[3A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[3A\u001b[2K\u001b[20A\u001b[2K\u001b[3A\u001b[2K\u001b[20A\u001b[2K\u001b[3A\u001b[2K\u001b[20A\u001b[2K\u001b[3A\u001b[2K\u001b[20A\u001b[2K\u001b[3A\u001b[2K\u001b[20A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[20A\u001b[2K\u001b[3A\u001b[2K\u001b[20A\u001b[2K\u001b[3A\u001b[2K\u001b[20A\u001b[2K\u001b[3A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[3A\u001b[2K\u001b[20A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[3A\u001b[2K\u001b[20A\u001b[2K\u001b[3A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[20A\u001b[2K\u001b[3A\u001b[2K\u001b[20A\u001b[2K\u001b[3A\u001b[2K\u001b[20A\u001b[2K\u001b[3A\u001b[2K\u001b[20A\u001b[2K\u001b[3A\u001b[2K\u001b[20A\u001b[2K\u001b[3A\u001b[2K\u001b[20A\u001b[2K\u001b[3A\u001b[2K\u001b[20A\u001b[2K\u001b[3A\u001b[2K\u001b[20A\u001b[2K\u001b[3A\u001b[2K\u001b[20A\u001b[2K\u001b[3A\u001b[2K\u001b[20A\u001b[2K\u001b[3A\u001b[2K\u001b[20A\u001b[2K\u001b[3A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[3A\u001b[2K\u001b[20A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[20A\u001b[2K\u001b[3A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[3A\u001b[2K\u001b[20A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[20A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[18A\u001b[2K\u001b[17A\u001b[2K\u001b[16A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[14A\u001b[2K\u001b[14A\u001b[2K\u001b[14A\u001b[2K\u001b[14A\u001b[2K\u001b[14A\u001b[2K\u001b[14A\u001b[2K\u001b[14A\u001b[2K\u001b[14A\u001b[2K\u001b[14A\u001b[2K\u001b[14A\u001b[2K\u001b[14A\u001b[2K\u001b[14A\u001b[2K\u001b[14A\u001b[2K\u001b[14A\u001b[2K\u001b[14A\u001b[2K\u001b[14A\u001b[2K\u001b[14A\u001b[2K\u001b[13A\u001b[2K\u001b[13A\u001b[2K\u001b[12A\u001b[2K\u001b[12A\u001b[2K\u001b[12A\u001b[2K\u001b[12A\u001b[2K\u001b[12A\u001b[2K\u001b[12A\u001b[2K\u001b[12A\u001b[2K\u001b[12A\u001b[2K\u001b[12A\u001b[2K\u001b[12A\u001b[2K\u001b[12A\u001b[2K\u001b[12A\u001b[2K\u001b[12A\u001b[2K\u001b[12A\u001b[2K\u001b[12A\u001b[2K\u001b[12A\u001b[2K\u001b[12A\u001b[2K\u001b[12A\u001b[2K\u001b[12A\u001b[2K\u001b[12A\u001b[2K\u001b[12A\u001b[2K\u001b[12A\u001b[2K\u001b[12A\u001b[2K\u001b[12A\u001b[2K\u001b[12A\u001b[2K\u001b[12A\u001b[2K\u001b[12A\u001b[2K\u001b[12A\u001b[2K\u001b[12A\u001b[2K\u001b[12A\u001b[2K\u001b[12A\u001b[2K\u001b[12A\u001b[2K\u001b[12A\u001b[2K\u001b[12A\u001b[2K\u001b[12A\u001b[2K\u001b[12A\u001b[2K\u001b[12A\u001b[2K\u001b[12A\u001b[2K\u001b[12A\u001b[2K\u001b[12A\u001b[2K\u001b[12A\u001b[2K\u001b[12A\u001b[2K\u001b[12A\u001b[2K\u001b[12A\u001b[2K\u001b[12A\u001b[2K\u001b[12A\u001b[2K\u001b[12A\u001b[2K\u001b[12A\u001b[2K\u001b[12A\u001b[2K\u001b[12A\u001b[2K\u001b[12A\u001b[2K\u001b[12A\u001b[2K\u001b[12A\u001b[2K\u001b[11A\u001b[2K\u001b[10A\u001b[2K\u001b[10A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[1A\u001b[2KDigest: sha256:306b5b7fbf244a708c4bb2380ec127561912704a2bcc463e11348fa1300afa8e\n",
      "Status: Downloaded newer image for nvcr.io/nvidia/tritonserver:22.12-py3\n",
      "91448f589d0cda0cbd2499deb4df84595222f1b02815d1e02f883207b1d677dd\n"
     ]
    }
   ],
   "source": [
    "!docker run --gpus=all -d --shm-size=4G --rm -p8000:8000 -p8001:8001 -p8002:8002 -v$(pwd)/model_repo:/model_repository nvcr.io/nvidia/tritonserver:22.12-py3 tritonserver --model-repository=/model_repository --exit-on-error=false --strict-model-config=false\n",
    "# time.sleep(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4235d76d",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "CONTAINER_ID=!docker container ls -q\n",
    "FIRST_CONTAINER_ID = CONTAINER_ID[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd7764f3",
   "metadata": {},
   "source": [
    "Uncomment the next cell and run it to view the container logs and understand Triton model loading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c0b58823",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=============================\n",
      "== Triton Inference Server ==\n",
      "=============================\n",
      "\n",
      "NVIDIA Release 22.12 (build 50109463)\n",
      "Triton Server Version 2.29.0\n",
      "\n",
      "Copyright (c) 2018-2022, NVIDIA CORPORATION & AFFILIATES.  All rights reserved.\n",
      "\n",
      "Various files include modifications (c) NVIDIA CORPORATION & AFFILIATES.  All rights reserved.\n",
      "\n",
      "This container image and its contents are governed by the NVIDIA Deep Learning Container License.\n",
      "By pulling and using the container, you accept the terms and conditions of this license:\n",
      "https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license\n",
      "\n",
      "NOTE: CUDA Forward Compatibility mode ENABLED.\n",
      "  Using CUDA 11.8 driver version 520.61.05 with kernel driver version 510.47.03.\n",
      "  See https://docs.nvidia.com/deploy/cuda-compatibility/ for details.\n",
      "\n",
      "Warning: '--strict-model-config' has been deprecated! Please use '--disable-auto-complete-config' instead.\n",
      "I0217 05:59:47.318165 1 pinned_memory_manager.cc:240] Pinned memory pool is created at '0x7f3f1e000000' with size 268435456\n",
      "I0217 05:59:47.320371 1 cuda_memory_manager.cc:105] CUDA memory pool is created on device 0 with size 67108864\n",
      "W0217 05:59:47.324396 1 model_lifecycle.cc:107] ignore version directory '.ipynb_checkpoints' which fails to convert to integral number\n",
      "W0217 05:59:47.324432 1 model_lifecycle.cc:107] ignore version directory 'model' which fails to convert to integral number\n",
      "W0217 05:59:47.324440 1 model_lifecycle.cc:107] ignore version directory 'tokenizer' which fails to convert to integral number\n",
      "I0217 05:59:47.324452 1 model_lifecycle.cc:459] loading: e2e:1\n",
      "I0217 05:59:48.591184 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: e2e_0 (GPU device 0)\n",
      "Collecting torch\n",
      "  Downloading torch-1.13.1-cp38-cp38-manylinux1_x86_64.whl (887.4 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 887.4/887.4 MB 854.6 kB/s eta 0:00:00\n",
      "Collecting transformers==4.9.1\n",
      "  Downloading transformers-4.9.1-py3-none-any.whl (2.6 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.6/2.6 MB 30.1 MB/s eta 0:00:00\n",
      "Collecting tokenizers<0.11,>=0.10.1\n",
      "  Downloading tokenizers-0.10.3-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.3/3.3 MB 30.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: requests in /usr/lib/python3/dist-packages (from transformers==4.9.1->-r /model_repository/e2e/requirements.txt (line 2)) (2.22.0)\n",
      "Collecting tqdm>=4.27\n",
      "  Downloading tqdm-4.64.1-py2.py3-none-any.whl (78 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 78.5/78.5 kB 2.1 MB/s eta 0:00:00\n",
      "Collecting huggingface-hub==0.0.12\n",
      "  Downloading huggingface_hub-0.0.12-py3-none-any.whl (37 kB)\n",
      "Collecting regex!=2019.12.17\n",
      "  Downloading regex-2022.10.31-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (772 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 772.3/772.3 kB 87.3 MB/s eta 0:00:00\n",
      "Collecting pyyaml>=5.1\n",
      "  Downloading PyYAML-6.0-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (701 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 701.2/701.2 kB 90.3 MB/s eta 0:00:00\n",
      "Collecting packaging\n",
      "  Downloading packaging-23.0-py3-none-any.whl (42 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 42.7/42.7 kB 12.7 MB/s eta 0:00:00\n",
      "Collecting sacremoses\n",
      "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 880.6/880.6 kB 89.9 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers==4.9.1->-r /model_repository/e2e/requirements.txt (line 2)) (1.23.5)\n",
      "Collecting filelock\n",
      "  Downloading filelock-3.9.0-py3-none-any.whl (9.7 kB)\n",
      "Collecting typing-extensions\n",
      "  Downloading typing_extensions-4.5.0-py3-none-any.whl (27 kB)\n",
      "Collecting nvidia-cublas-cu11==11.10.3.66\n",
      "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 317.1/317.1 MB 4.8 MB/s eta 0:00:00\n",
      "Collecting nvidia-cuda-runtime-cu11==11.7.99\n",
      "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 849.3/849.3 kB 90.4 MB/s eta 0:00:00\n",
      "Collecting nvidia-cuda-nvrtc-cu11==11.7.99\n",
      "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 21.0/21.0 MB 76.5 MB/s eta 0:00:00\n",
      "Collecting nvidia-cudnn-cu11==8.5.0.96\n",
      "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 557.1/557.1 MB 2.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: wheel in /usr/local/lib/python3.8/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch->-r /model_repository/e2e/requirements.txt (line 1)) (0.38.4)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch->-r /model_repository/e2e/requirements.txt (line 1)) (65.6.3)\n",
      "Requirement already satisfied: six in /usr/lib/python3/dist-packages (from sacremoses->transformers==4.9.1->-r /model_repository/e2e/requirements.txt (line 2)) (1.14.0)\n",
      "Collecting click\n",
      "  Downloading click-8.1.3-py3-none-any.whl (96 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 96.6/96.6 kB 29.9 MB/s eta 0:00:00\n",
      "Collecting joblib\n",
      "  Downloading joblib-1.2.0-py3-none-any.whl (297 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 298.0/298.0 kB 56.0 MB/s eta 0:00:00\n",
      "Building wheels for collected packages: sacremoses\n",
      "  Building wheel for sacremoses (setup.py): started\n",
      "  Building wheel for sacremoses (setup.py): finished with status 'done'\n",
      "  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895241 sha256=c9cce05d28cd9756e405f28d29ec973ac8feeada2a387dc2446cb9bd1923cb5d\n",
      "  Stored in directory: /root/.cache/pip/wheels/64/a3/ff/01dc060d7fc51176b3ce7cf1561466a12e658164b594747547\n",
      "Successfully built sacremoses\n",
      "Installing collected packages: tokenizers, typing-extensions, tqdm, regex, pyyaml, packaging, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cublas-cu11, joblib, filelock, click, sacremoses, nvidia-cudnn-cu11, huggingface-hub, transformers, torch\n",
      "Successfully installed click-8.1.3 filelock-3.9.0 huggingface-hub-0.0.12 joblib-1.2.0 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 packaging-23.0 pyyaml-6.0 regex-2022.10.31 sacremoses-0.0.53 tokenizers-0.10.3 torch-1.13.1 tqdm-4.64.1 transformers-4.9.1 typing-extensions-4.5.0\n",
      "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 23.0\n",
      "[notice] To update, run: python3 -m pip install --upgrade pip\n",
      "I0217 06:01:10.720377 1 model_lifecycle.cc:694] successfully loaded 'e2e' version 1\n",
      "I0217 06:01:10.720498 1 server.cc:563] \n",
      "+------------------+------+\n",
      "| Repository Agent | Path |\n",
      "+------------------+------+\n",
      "+------------------+------+\n",
      "\n",
      "I0217 06:01:10.720569 1 server.cc:590] \n",
      "+---------+-------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| Backend | Path                                                  | Config                                                                                                                                                        |\n",
      "+---------+-------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| python  | /opt/tritonserver/backends/python/libtriton_python.so | {\"cmdline\":{\"auto-complete-config\":\"true\",\"min-compute-capability\":\"6.000000\",\"backend-directory\":\"/opt/tritonserver/backends\",\"default-max-batch-size\":\"4\"}} |\n",
      "+---------+-------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n",
      "I0217 06:01:10.720607 1 server.cc:633] \n",
      "+-------+---------+--------+\n",
      "| Model | Version | Status |\n",
      "+-------+---------+--------+\n",
      "| e2e   | 1       | READY  |\n",
      "+-------+---------+--------+\n",
      "\n",
      "I0217 06:01:10.744052 1 metrics.cc:864] Collecting metrics for GPU 0: Tesla T4\n",
      "I0217 06:01:10.744295 1 metrics.cc:757] Collecting CPU metrics\n",
      "I0217 06:01:10.744443 1 tritonserver.cc:2264] \n",
      "+----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| Option                           | Value                                                                                                                                                                                                |\n",
      "+----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| server_id                        | triton                                                                                                                                                                                               |\n",
      "| server_version                   | 2.29.0                                                                                                                                                                                               |\n",
      "| server_extensions                | classification sequence model_repository model_repository(unload_dependents) schedule_policy model_configuration system_shared_memory cuda_shared_memory binary_tensor_data statistics trace logging |\n",
      "| model_repository_path[0]         | /model_repository                                                                                                                                                                                    |\n",
      "| model_control_mode               | MODE_NONE                                                                                                                                                                                            |\n",
      "| strict_model_config              | 0                                                                                                                                                                                                    |\n",
      "| rate_limit                       | OFF                                                                                                                                                                                                  |\n",
      "| pinned_memory_pool_byte_size     | 268435456                                                                                                                                                                                            |\n",
      "| cuda_memory_pool_byte_size{0}    | 67108864                                                                                                                                                                                             |\n",
      "| response_cache_byte_size         | 0                                                                                                                                                                                                    |\n",
      "| min_supported_compute_capability | 6.0                                                                                                                                                                                                  |\n",
      "| strict_readiness                 | 1                                                                                                                                                                                                    |\n",
      "| exit_timeout                     | 30                                                                                                                                                                                                   |\n",
      "+----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n",
      "I0217 06:01:10.745582 1 grpc_server.cc:4819] Started GRPCInferenceService at 0.0.0.0:8001\n",
      "I0217 06:01:10.745867 1 http_server.cc:3477] Started HTTPService at 0.0.0.0:8000\n",
      "I0217 06:01:10.786935 1 http_server.cc:184] Started Metrics Service at 0.0.0.0:8002\n"
     ]
    }
   ],
   "source": [
    "# !docker logs $FIRST_CONTAINER_ID -f\n",
    "!docker logs $FIRST_CONTAINER_ID"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7233303",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Test TensorRT model by invoking the local Triton Server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d029f98d",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Start a local Triton client\n",
    "try:\n",
    "    triton_client = http_client.InferenceServerClient(url=\"localhost:8000\", verbose=True)\n",
    "except Exception as e:\n",
    "    print(\"context creation failed: \" + str(e))\n",
    "    sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "555eb91c",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Create inputs to send to Triton\n",
    "model_name = \"e2e\"\n",
    "\n",
    "text_inputs = [\"Sentence 1\", \"Sentence 2\"]\n",
    "\n",
    "# Text is passed to Trtion as BYTES\n",
    "inputs = []\n",
    "inputs.append(http_client.InferInput(\"INPUT0\", [len(text_inputs), 1], \"BYTES\"))\n",
    "\n",
    "# We need to structure batch inputs as such\n",
    "batch_request = [[text_inputs[i]] for i in range(len(text_inputs))]\n",
    "input0_real = np.array(batch_request, dtype=np.object_)\n",
    "\n",
    "inputs[0].set_data_from_numpy(input0_real, binary_data=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "42d95542",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "outputs = []\n",
    "\n",
    "outputs.append(http_client.InferRequestedOutput(\"SENT_EMBED\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f3b80733",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POST /v2/models/e2e/infer, headers None\n",
      "{\"inputs\":[{\"name\":\"INPUT0\",\"shape\":[2,1],\"datatype\":\"BYTES\",\"data\":[\"Sentence 1\",\"Sentence 2\"]}],\"outputs\":[{\"name\":\"SENT_EMBED\",\"parameters\":{\"binary_data\":true}}]}\n",
      "<HTTPSocketPoolResponse status=200 headers={'content-type': 'application/octet-stream', 'inference-header-content-length': '148', 'content-length': '8340'}>\n",
      "bytearray(b'{\"model_name\":\"e2e\",\"model_version\":\"1\",\"outputs\":[{\"name\":\"SENT_EMBED\",\"datatype\":\"FP32\",\"shape\":[2,1024],\"parameters\":{\"binary_data_size\":8192}}]}')\n"
     ]
    }
   ],
   "source": [
    "results = triton_client.infer(model_name=model_name, inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c7d56e6f",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "outputs0 = results.as_numpy(\"SENT_EMBED\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b889349b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 1\n",
      "[-0.00097987 -0.00352379 -0.004177   ... -0.00120587 -0.00202981\n",
      " -0.00294534]\n",
      "Sentence 2\n",
      "[-0.00035618 -0.0042098  -0.00419457 ... -0.00180162 -0.00149669\n",
      " -0.0010363 ]\n"
     ]
    }
   ],
   "source": [
    "for idx, output in enumerate(outputs0):\n",
    "    print(text_inputs[idx])\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "307a293d",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91448f589d0c\n"
     ]
    }
   ],
   "source": [
    "# Use this to stop the container that was started in detached mode\n",
    "!docker kill $FIRST_CONTAINER_ID"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc8cbf0e",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd1b0a2",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Part 4 - Deploy Triton to SageMaker MME Endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3160c5",
   "metadata": {},
   "source": [
    "# MME Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "21adbe70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'785573368785.dkr.ecr.us-east-1.amazonaws.com/sagemaker-tritonserver:22.12-py3'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if region not in account_id_map.keys():\n",
    "    raise (\"UNSUPPORTED REGION\")\n",
    "\n",
    "base = \"amazonaws.com.cn\" if region.startswith(\"cn-\") else \"amazonaws.com\"\n",
    "\n",
    "triton_image_uri = \"{account_id}.dkr.ecr.{region}.{base}/sagemaker-tritonserver:22.12-py3\".format(\n",
    "    account_id=account_id_map[region], region=region, base=base\n",
    ")\n",
    "\n",
    "triton_image_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1e2776c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker-us-east-1-414210492846\n"
     ]
    }
   ],
   "source": [
    "bucket = sagemaker_session.default_bucket()\n",
    "print(bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ee516a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar -C model_repo_5/ -czf e2e-5.tar.gz e2e-5\n",
    "prefix = 'bert_mme_gpu'\n",
    "e2e_uri = sagemaker_session.upload_data(path=\"e2e-5.tar.gz\", key_prefix=prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ff0c21a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-02-17 06:30:11  834120513 e2e-2.tar.gz\n",
      "2023-02-17 06:09:58  834120588 e2e.tar.gz\n"
     ]
    }
   ],
   "source": [
    "model_data_url = f\"s3://{bucket}/{prefix}/\"\n",
    "!aws s3 ls $model_data_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6b4b6416",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data_url = f\"s3://{bucket}/{prefix}/\"\n",
    "\n",
    "container = {\n",
    "    \"Image\": triton_image_uri,\n",
    "    \"ModelDataUrl\": model_data_url,\n",
    "    \"Mode\": \"MultiModel\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a0c46beb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Arn: arn:aws:sagemaker:us-east-1:414210492846:model/triton-e2e-2023-02-17-06-10-23\n"
     ]
    }
   ],
   "source": [
    "sm_model_name = \"triton-e2e-\" + time.strftime(\"%Y-%m-%d-%H-%M-%S\", time.gmtime())\n",
    "\n",
    "create_model_response = sm_client.create_model(\n",
    "    ModelName=sm_model_name, ExecutionRoleArn=role, PrimaryContainer=container\n",
    ")\n",
    "\n",
    "print(\"Model Arn: \" + create_model_response[\"ModelArn\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "295dd696",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Endpoint Config Arn: arn:aws:sagemaker:us-east-1:414210492846:endpoint-config/triton-e2e-2023-02-17-07-55-14\n"
     ]
    }
   ],
   "source": [
    "endpoint_config_name = \"triton-e2e-\" + time.strftime(\"%Y-%m-%d-%H-%M-%S\", time.gmtime())\n",
    "\n",
    "create_endpoint_config_response = sm_client.create_endpoint_config(\n",
    "    EndpointConfigName=endpoint_config_name,\n",
    "    ProductionVariants=[\n",
    "        {\n",
    "            \"InstanceType\": \"ml.g4dn.2xlarge\",\n",
    "            \"InitialVariantWeight\": 1,\n",
    "            \"InitialInstanceCount\": 1,\n",
    "            \"ModelName\": sm_model_name,\n",
    "            \"VariantName\": \"AllTraffic\",\n",
    "        }\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(\"Endpoint Config Arn: \" + create_endpoint_config_response[\"EndpointConfigArn\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "60672c88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Endpoint Arn: arn:aws:sagemaker:us-east-1:414210492846:endpoint/triton-e2e-2023-02-17-07-55-22\n"
     ]
    }
   ],
   "source": [
    "endpoint_name = \"triton-e2e-\" + time.strftime(\"%Y-%m-%d-%H-%M-%S\", time.gmtime())\n",
    "\n",
    "create_endpoint_response = sm_client.create_endpoint(\n",
    "    EndpointName=endpoint_name, EndpointConfigName=endpoint_config_name\n",
    ")\n",
    "\n",
    "print(\"Endpoint Arn: \" + create_endpoint_response[\"EndpointArn\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3eab274a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: Creating\n",
      "Status: Creating\n",
      "Status: Creating\n",
      "Status: Creating\n",
      "Status: Creating\n",
      "Status: Creating\n",
      "Status: InService\n",
      "Arn: arn:aws:sagemaker:us-east-1:414210492846:endpoint/triton-e2e-2023-02-17-07-55-22\n",
      "Status: InService\n"
     ]
    }
   ],
   "source": [
    "resp = sm_client.describe_endpoint(EndpointName=endpoint_name)\n",
    "status = resp[\"EndpointStatus\"]\n",
    "print(\"Status: \" + status)\n",
    "\n",
    "while status == \"Creating\":\n",
    "    time.sleep(60)\n",
    "    resp = sm_client.describe_endpoint(EndpointName=endpoint_name)\n",
    "    status = resp[\"EndpointStatus\"]\n",
    "    print(\"Status: \" + status)\n",
    "\n",
    "print(\"Arn: \" + resp[\"EndpointArn\"])\n",
    "print(\"Status: \" + status)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be946b5b",
   "metadata": {},
   "source": [
    "## Test endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e9d070a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sentence 1', 'Sentence 2']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4cc3960d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tritonclient.http.InferInput at 0x7f02dc867610>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "http_client.InferInput(\"INPUT0\", [len(text_inputs), 1], \"BYTES\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1da71be2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_inputs = [\"Sentence 1\", \"Sentence 2\"]\n",
    "\n",
    "inputs = []\n",
    "inputs.append(http_client.InferInput(\"INPUT0\", [len(text_inputs), 1], \"BYTES\"))\n",
    "\n",
    "batch_request = [[text_inputs[i]] for i in range(len(text_inputs))]\n",
    "\n",
    "input0_real = np.array(batch_request, dtype=np.object_)\n",
    "\n",
    "inputs[0].set_data_from_numpy(input0_real, binary_data=False)\n",
    "\n",
    "len(input0_real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d91213bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = []\n",
    "\n",
    "outputs.append(http_client.InferRequestedOutput(\"SENT_EMBED\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a218fc36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tritonclient.http.InferRequestedOutput at 0x7f0252033100>]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "51a936c2",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"inputs\":[{\"name\":\"INPUT0\",\"shape\":[2,1],\"datatype\":\"BYTES\",\"data\":[\"Sentence 1\",\"Sentence 2\"]}],\"outputs\":[{\"name\":\"SENT_EMBED\",\"parameters\":{\"binary_data\":true}}]}\n"
     ]
    }
   ],
   "source": [
    "request_body, header_length = http_client.InferenceServerClient.generate_request_body(\n",
    "    inputs, outputs=outputs\n",
    ")\n",
    "\n",
    "print(request_body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "48695904",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = sm_runtime_client.invoke_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    # ContentType=\"application/vnd.sagemaker-triton.binary+json;json-header-size={}\".format(\n",
    "        # header_length\n",
    "    # ),\n",
    "    ContentType='application/octet-stream',\n",
    "    Body=request_body,\n",
    "    TargetModel='e2e-2.tar.gz'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "454dec09",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 1\n",
      "[-0.00097987 -0.00352379 -0.004177   ... -0.00120587 -0.00202981\n",
      " -0.00294534]\n",
      "Sentence 2\n",
      "[-0.00035618 -0.0042098  -0.00419457 ... -0.00180162 -0.00149669\n",
      " -0.0010363 ]\n"
     ]
    }
   ],
   "source": [
    "header_length_prefix = \"application/vnd.sagemaker-triton.binary+json;json-header-size=\"\n",
    "header_length_str = response[\"ContentType\"][len(header_length_prefix) :]\n",
    "\n",
    "# Read response body\n",
    "result = http_client.InferenceServerClient.parse_response_body(\n",
    "    response[\"Body\"].read(), header_length=int(header_length_str)\n",
    ")\n",
    "\n",
    "outputs_data = result.as_numpy(\"SENT_EMBED\")\n",
    "\n",
    "for idx, output in enumerate(outputs_data):\n",
    "    print(text_inputs[idx])\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f9d9e7c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "invoking model e2e-1.tar.gz\n",
      "Sentence 1\n",
      "[-0.00097987 -0.00352379 -0.004177   ... -0.00120587 -0.00202981\n",
      " -0.00294534]\n",
      "Sentence 2\n",
      "[-0.00035618 -0.0042098  -0.00419457 ... -0.00180162 -0.00149669\n",
      " -0.0010363 ]\n",
      "Execution time: 81.8214521408081 seconds\n",
      "invoking model e2e-2.tar.gz\n",
      "Sentence 1\n",
      "[-0.00097987 -0.00352379 -0.004177   ... -0.00120587 -0.00202981\n",
      " -0.00294534]\n",
      "Sentence 2\n",
      "[-0.00035618 -0.0042098  -0.00419457 ... -0.00180162 -0.00149669\n",
      " -0.0010363 ]\n",
      "Execution time: 21.268391132354736 seconds\n",
      "invoking model e2e-3.tar.gz\n",
      "Sentence 1\n",
      "[-0.00097987 -0.00352379 -0.004177   ... -0.00120587 -0.00202981\n",
      " -0.00294534]\n",
      "Sentence 2\n",
      "[-0.00035618 -0.0042098  -0.00419457 ... -0.00180162 -0.00149669\n",
      " -0.0010363 ]\n",
      "Execution time: 21.287919759750366 seconds\n",
      "invoking model e2e-4.tar.gz\n",
      "Sentence 1\n",
      "[-0.00097987 -0.00352379 -0.004177   ... -0.00120587 -0.00202981\n",
      " -0.00294534]\n",
      "Sentence 2\n",
      "[-0.00035618 -0.0042098  -0.00419457 ... -0.00180162 -0.00149669\n",
      " -0.0010363 ]\n",
      "Execution time: 21.50484848022461 seconds\n",
      "invoking model e2e-5.tar.gz\n",
      "Sentence 1\n",
      "[-0.00097987 -0.00352379 -0.004177   ... -0.00120587 -0.00202981\n",
      " -0.00294534]\n",
      "Sentence 2\n",
      "[-0.00035618 -0.0042098  -0.00419457 ... -0.00180162 -0.00149669\n",
      " -0.0010363 ]\n",
      "Execution time: 21.297184467315674 seconds\n",
      "invoking model e2e-1.tar.gz\n",
      "Sentence 1\n",
      "[-0.00097987 -0.00352379 -0.004177   ... -0.00120587 -0.00202981\n",
      " -0.00294534]\n",
      "Sentence 2\n",
      "[-0.00035618 -0.0042098  -0.00419457 ... -0.00180162 -0.00149669\n",
      " -0.0010363 ]\n",
      "Execution time: 0.04559683799743652 seconds\n",
      "invoking model e2e-2.tar.gz\n",
      "Sentence 1\n",
      "[-0.00097987 -0.00352379 -0.004177   ... -0.00120587 -0.00202981\n",
      " -0.00294534]\n",
      "Sentence 2\n",
      "[-0.00035618 -0.0042098  -0.00419457 ... -0.00180162 -0.00149669\n",
      " -0.0010363 ]\n",
      "Execution time: 0.04560112953186035 seconds\n",
      "invoking model e2e-3.tar.gz\n",
      "Sentence 1\n",
      "[-0.00097987 -0.00352379 -0.004177   ... -0.00120587 -0.00202981\n",
      " -0.00294534]\n",
      "Sentence 2\n",
      "[-0.00035618 -0.0042098  -0.00419457 ... -0.00180162 -0.00149669\n",
      " -0.0010363 ]\n",
      "Execution time: 0.04593849182128906 seconds\n",
      "invoking model e2e-4.tar.gz\n",
      "Sentence 1\n",
      "[-0.00097987 -0.00352379 -0.004177   ... -0.00120587 -0.00202981\n",
      " -0.00294534]\n",
      "Sentence 2\n",
      "[-0.00035618 -0.0042098  -0.00419457 ... -0.00180162 -0.00149669\n",
      " -0.0010363 ]\n",
      "Execution time: 0.04402041435241699 seconds\n",
      "invoking model e2e-5.tar.gz\n",
      "Sentence 1\n",
      "[-0.00097987 -0.00352379 -0.004177   ... -0.00120587 -0.00202981\n",
      " -0.00294534]\n",
      "Sentence 2\n",
      "[-0.00035618 -0.0042098  -0.00419457 ... -0.00180162 -0.00149669\n",
      " -0.0010363 ]\n",
      "Execution time: 0.04378509521484375 seconds\n",
      "invoking model e2e-1.tar.gz\n",
      "Sentence 1\n",
      "[-0.00097987 -0.00352379 -0.004177   ... -0.00120587 -0.00202981\n",
      " -0.00294534]\n",
      "Sentence 2\n",
      "[-0.00035618 -0.0042098  -0.00419457 ... -0.00180162 -0.00149669\n",
      " -0.0010363 ]\n",
      "Execution time: 0.0433042049407959 seconds\n",
      "invoking model e2e-2.tar.gz\n",
      "Sentence 1\n",
      "[-0.00097987 -0.00352379 -0.004177   ... -0.00120587 -0.00202981\n",
      " -0.00294534]\n",
      "Sentence 2\n",
      "[-0.00035618 -0.0042098  -0.00419457 ... -0.00180162 -0.00149669\n",
      " -0.0010363 ]\n",
      "Execution time: 0.043407440185546875 seconds\n",
      "invoking model e2e-3.tar.gz\n",
      "Sentence 1\n",
      "[-0.00097987 -0.00352379 -0.004177   ... -0.00120587 -0.00202981\n",
      " -0.00294534]\n",
      "Sentence 2\n",
      "[-0.00035618 -0.0042098  -0.00419457 ... -0.00180162 -0.00149669\n",
      " -0.0010363 ]\n",
      "Execution time: 0.04250288009643555 seconds\n",
      "invoking model e2e-4.tar.gz\n",
      "Sentence 1\n",
      "[-0.00097987 -0.00352379 -0.004177   ... -0.00120587 -0.00202981\n",
      " -0.00294534]\n",
      "Sentence 2\n",
      "[-0.00035618 -0.0042098  -0.00419457 ... -0.00180162 -0.00149669\n",
      " -0.0010363 ]\n",
      "Execution time: 0.04215884208679199 seconds\n",
      "invoking model e2e-5.tar.gz\n",
      "Sentence 1\n",
      "[-0.00097987 -0.00352379 -0.004177   ... -0.00120587 -0.00202981\n",
      " -0.00294534]\n",
      "Sentence 2\n",
      "[-0.00035618 -0.0042098  -0.00419457 ... -0.00180162 -0.00149669\n",
      " -0.0010363 ]\n",
      "Execution time: 0.044207096099853516 seconds\n",
      "invoking model e2e-1.tar.gz\n",
      "Sentence 1\n",
      "[-0.00097987 -0.00352379 -0.004177   ... -0.00120587 -0.00202981\n",
      " -0.00294534]\n",
      "Sentence 2\n",
      "[-0.00035618 -0.0042098  -0.00419457 ... -0.00180162 -0.00149669\n",
      " -0.0010363 ]\n",
      "Execution time: 0.0449678897857666 seconds\n",
      "invoking model e2e-2.tar.gz\n",
      "Sentence 1\n",
      "[-0.00097987 -0.00352379 -0.004177   ... -0.00120587 -0.00202981\n",
      " -0.00294534]\n",
      "Sentence 2\n",
      "[-0.00035618 -0.0042098  -0.00419457 ... -0.00180162 -0.00149669\n",
      " -0.0010363 ]\n",
      "Execution time: 0.043465375900268555 seconds\n",
      "invoking model e2e-3.tar.gz\n",
      "Sentence 1\n",
      "[-0.00097987 -0.00352379 -0.004177   ... -0.00120587 -0.00202981\n",
      " -0.00294534]\n",
      "Sentence 2\n",
      "[-0.00035618 -0.0042098  -0.00419457 ... -0.00180162 -0.00149669\n",
      " -0.0010363 ]\n",
      "Execution time: 0.043320655822753906 seconds\n",
      "invoking model e2e-4.tar.gz\n",
      "Sentence 1\n",
      "[-0.00097987 -0.00352379 -0.004177   ... -0.00120587 -0.00202981\n",
      " -0.00294534]\n",
      "Sentence 2\n",
      "[-0.00035618 -0.0042098  -0.00419457 ... -0.00180162 -0.00149669\n",
      " -0.0010363 ]\n",
      "Execution time: 0.04258418083190918 seconds\n",
      "invoking model e2e-5.tar.gz\n",
      "Sentence 1\n",
      "[-0.00097987 -0.00352379 -0.004177   ... -0.00120587 -0.00202981\n",
      " -0.00294534]\n",
      "Sentence 2\n",
      "[-0.00035618 -0.0042098  -0.00419457 ... -0.00180162 -0.00149669\n",
      " -0.0010363 ]\n",
      "Execution time: 0.04313182830810547 seconds\n",
      "invoking model e2e-1.tar.gz\n",
      "Sentence 1\n",
      "[-0.00097987 -0.00352379 -0.004177   ... -0.00120587 -0.00202981\n",
      " -0.00294534]\n",
      "Sentence 2\n",
      "[-0.00035618 -0.0042098  -0.00419457 ... -0.00180162 -0.00149669\n",
      " -0.0010363 ]\n",
      "Execution time: 0.044747114181518555 seconds\n",
      "invoking model e2e-2.tar.gz\n",
      "Sentence 1\n",
      "[-0.00097987 -0.00352379 -0.004177   ... -0.00120587 -0.00202981\n",
      " -0.00294534]\n",
      "Sentence 2\n",
      "[-0.00035618 -0.0042098  -0.00419457 ... -0.00180162 -0.00149669\n",
      " -0.0010363 ]\n",
      "Execution time: 0.04483199119567871 seconds\n",
      "invoking model e2e-3.tar.gz\n",
      "Sentence 1\n",
      "[-0.00097987 -0.00352379 -0.004177   ... -0.00120587 -0.00202981\n",
      " -0.00294534]\n",
      "Sentence 2\n",
      "[-0.00035618 -0.0042098  -0.00419457 ... -0.00180162 -0.00149669\n",
      " -0.0010363 ]\n",
      "Execution time: 0.04445075988769531 seconds\n",
      "invoking model e2e-4.tar.gz\n",
      "Sentence 1\n",
      "[-0.00097987 -0.00352379 -0.004177   ... -0.00120587 -0.00202981\n",
      " -0.00294534]\n",
      "Sentence 2\n",
      "[-0.00035618 -0.0042098  -0.00419457 ... -0.00180162 -0.00149669\n",
      " -0.0010363 ]\n",
      "Execution time: 0.04469418525695801 seconds\n",
      "invoking model e2e-5.tar.gz\n",
      "Sentence 1\n",
      "[-0.00097987 -0.00352379 -0.004177   ... -0.00120587 -0.00202981\n",
      " -0.00294534]\n",
      "Sentence 2\n",
      "[-0.00035618 -0.0042098  -0.00419457 ... -0.00180162 -0.00149669\n",
      " -0.0010363 ]\n",
      "Execution time: 0.04502058029174805 seconds\n",
      "invoking model e2e-1.tar.gz\n",
      "Sentence 1\n",
      "[-0.00097987 -0.00352379 -0.004177   ... -0.00120587 -0.00202981\n",
      " -0.00294534]\n",
      "Sentence 2\n",
      "[-0.00035618 -0.0042098  -0.00419457 ... -0.00180162 -0.00149669\n",
      " -0.0010363 ]\n",
      "Execution time: 0.04494309425354004 seconds\n",
      "invoking model e2e-2.tar.gz\n",
      "Sentence 1\n",
      "[-0.00097987 -0.00352379 -0.004177   ... -0.00120587 -0.00202981\n",
      " -0.00294534]\n",
      "Sentence 2\n",
      "[-0.00035618 -0.0042098  -0.00419457 ... -0.00180162 -0.00149669\n",
      " -0.0010363 ]\n",
      "Execution time: 0.044519662857055664 seconds\n",
      "invoking model e2e-3.tar.gz\n",
      "Sentence 1\n",
      "[-0.00097987 -0.00352379 -0.004177   ... -0.00120587 -0.00202981\n",
      " -0.00294534]\n",
      "Sentence 2\n",
      "[-0.00035618 -0.0042098  -0.00419457 ... -0.00180162 -0.00149669\n",
      " -0.0010363 ]\n",
      "Execution time: 0.043776512145996094 seconds\n",
      "invoking model e2e-4.tar.gz\n",
      "Sentence 1\n",
      "[-0.00097987 -0.00352379 -0.004177   ... -0.00120587 -0.00202981\n",
      " -0.00294534]\n",
      "Sentence 2\n",
      "[-0.00035618 -0.0042098  -0.00419457 ... -0.00180162 -0.00149669\n",
      " -0.0010363 ]\n",
      "Execution time: 0.04445385932922363 seconds\n",
      "invoking model e2e-5.tar.gz\n",
      "Sentence 1\n",
      "[-0.00097987 -0.00352379 -0.004177   ... -0.00120587 -0.00202981\n",
      " -0.00294534]\n",
      "Sentence 2\n",
      "[-0.00035618 -0.0042098  -0.00419457 ... -0.00180162 -0.00149669\n",
      " -0.0010363 ]\n",
      "Execution time: 0.04317307472229004 seconds\n",
      "invoking model e2e-1.tar.gz\n",
      "Sentence 1\n",
      "[-0.00097987 -0.00352379 -0.004177   ... -0.00120587 -0.00202981\n",
      " -0.00294534]\n",
      "Sentence 2\n",
      "[-0.00035618 -0.0042098  -0.00419457 ... -0.00180162 -0.00149669\n",
      " -0.0010363 ]\n",
      "Execution time: 0.04526042938232422 seconds\n",
      "invoking model e2e-2.tar.gz\n",
      "Sentence 1\n",
      "[-0.00097987 -0.00352379 -0.004177   ... -0.00120587 -0.00202981\n",
      " -0.00294534]\n",
      "Sentence 2\n",
      "[-0.00035618 -0.0042098  -0.00419457 ... -0.00180162 -0.00149669\n",
      " -0.0010363 ]\n",
      "Execution time: 0.04390907287597656 seconds\n",
      "invoking model e2e-3.tar.gz\n",
      "Sentence 1\n",
      "[-0.00097987 -0.00352379 -0.004177   ... -0.00120587 -0.00202981\n",
      " -0.00294534]\n",
      "Sentence 2\n",
      "[-0.00035618 -0.0042098  -0.00419457 ... -0.00180162 -0.00149669\n",
      " -0.0010363 ]\n",
      "Execution time: 0.04346799850463867 seconds\n",
      "invoking model e2e-4.tar.gz\n",
      "Sentence 1\n",
      "[-0.00097987 -0.00352379 -0.004177   ... -0.00120587 -0.00202981\n",
      " -0.00294534]\n",
      "Sentence 2\n",
      "[-0.00035618 -0.0042098  -0.00419457 ... -0.00180162 -0.00149669\n",
      " -0.0010363 ]\n",
      "Execution time: 0.04700016975402832 seconds\n",
      "invoking model e2e-5.tar.gz\n",
      "Sentence 1\n",
      "[-0.00097987 -0.00352379 -0.004177   ... -0.00120587 -0.00202981\n",
      " -0.00294534]\n",
      "Sentence 2\n",
      "[-0.00035618 -0.0042098  -0.00419457 ... -0.00180162 -0.00149669\n",
      " -0.0010363 ]\n",
      "Execution time: 0.04419589042663574 seconds\n",
      "invoking model e2e-1.tar.gz\n",
      "Sentence 1\n",
      "[-0.00097987 -0.00352379 -0.004177   ... -0.00120587 -0.00202981\n",
      " -0.00294534]\n",
      "Sentence 2\n",
      "[-0.00035618 -0.0042098  -0.00419457 ... -0.00180162 -0.00149669\n",
      " -0.0010363 ]\n",
      "Execution time: 0.04509544372558594 seconds\n",
      "invoking model e2e-2.tar.gz\n",
      "Sentence 1\n",
      "[-0.00097987 -0.00352379 -0.004177   ... -0.00120587 -0.00202981\n",
      " -0.00294534]\n",
      "Sentence 2\n",
      "[-0.00035618 -0.0042098  -0.00419457 ... -0.00180162 -0.00149669\n",
      " -0.0010363 ]\n",
      "Execution time: 0.04328751564025879 seconds\n",
      "invoking model e2e-3.tar.gz\n",
      "Sentence 1\n",
      "[-0.00097987 -0.00352379 -0.004177   ... -0.00120587 -0.00202981\n",
      " -0.00294534]\n",
      "Sentence 2\n",
      "[-0.00035618 -0.0042098  -0.00419457 ... -0.00180162 -0.00149669\n",
      " -0.0010363 ]\n",
      "Execution time: 0.04289078712463379 seconds\n",
      "invoking model e2e-4.tar.gz\n",
      "Sentence 1\n",
      "[-0.00097987 -0.00352379 -0.004177   ... -0.00120587 -0.00202981\n",
      " -0.00294534]\n",
      "Sentence 2\n",
      "[-0.00035618 -0.0042098  -0.00419457 ... -0.00180162 -0.00149669\n",
      " -0.0010363 ]\n",
      "Execution time: 0.04419231414794922 seconds\n",
      "invoking model e2e-5.tar.gz\n",
      "Sentence 1\n",
      "[-0.00097987 -0.00352379 -0.004177   ... -0.00120587 -0.00202981\n",
      " -0.00294534]\n",
      "Sentence 2\n",
      "[-0.00035618 -0.0042098  -0.00419457 ... -0.00180162 -0.00149669\n",
      " -0.0010363 ]\n",
      "Execution time: 0.042726993560791016 seconds\n",
      "invoking model e2e-1.tar.gz\n",
      "Sentence 1\n",
      "[-0.00097987 -0.00352379 -0.004177   ... -0.00120587 -0.00202981\n",
      " -0.00294534]\n",
      "Sentence 2\n",
      "[-0.00035618 -0.0042098  -0.00419457 ... -0.00180162 -0.00149669\n",
      " -0.0010363 ]\n",
      "Execution time: 0.04220700263977051 seconds\n",
      "invoking model e2e-2.tar.gz\n",
      "Sentence 1\n",
      "[-0.00097987 -0.00352379 -0.004177   ... -0.00120587 -0.00202981\n",
      " -0.00294534]\n",
      "Sentence 2\n",
      "[-0.00035618 -0.0042098  -0.00419457 ... -0.00180162 -0.00149669\n",
      " -0.0010363 ]\n",
      "Execution time: 0.04233717918395996 seconds\n",
      "invoking model e2e-3.tar.gz\n",
      "Sentence 1\n",
      "[-0.00097987 -0.00352379 -0.004177   ... -0.00120587 -0.00202981\n",
      " -0.00294534]\n",
      "Sentence 2\n",
      "[-0.00035618 -0.0042098  -0.00419457 ... -0.00180162 -0.00149669\n",
      " -0.0010363 ]\n",
      "Execution time: 0.04217338562011719 seconds\n",
      "invoking model e2e-4.tar.gz\n",
      "Sentence 1\n",
      "[-0.00097987 -0.00352379 -0.004177   ... -0.00120587 -0.00202981\n",
      " -0.00294534]\n",
      "Sentence 2\n",
      "[-0.00035618 -0.0042098  -0.00419457 ... -0.00180162 -0.00149669\n",
      " -0.0010363 ]\n",
      "Execution time: 0.0413203239440918 seconds\n",
      "invoking model e2e-5.tar.gz\n",
      "Sentence 1\n",
      "[-0.00097987 -0.00352379 -0.004177   ... -0.00120587 -0.00202981\n",
      " -0.00294534]\n",
      "Sentence 2\n",
      "[-0.00035618 -0.0042098  -0.00419457 ... -0.00180162 -0.00149669\n",
      " -0.0010363 ]\n",
      "Execution time: 0.04193234443664551 seconds\n",
      "invoking model e2e-1.tar.gz\n",
      "Sentence 1\n",
      "[-0.00097987 -0.00352379 -0.004177   ... -0.00120587 -0.00202981\n",
      " -0.00294534]\n",
      "Sentence 2\n",
      "[-0.00035618 -0.0042098  -0.00419457 ... -0.00180162 -0.00149669\n",
      " -0.0010363 ]\n",
      "Execution time: 0.04149818420410156 seconds\n",
      "invoking model e2e-2.tar.gz\n",
      "Sentence 1\n",
      "[-0.00097987 -0.00352379 -0.004177   ... -0.00120587 -0.00202981\n",
      " -0.00294534]\n",
      "Sentence 2\n",
      "[-0.00035618 -0.0042098  -0.00419457 ... -0.00180162 -0.00149669\n",
      " -0.0010363 ]\n",
      "Execution time: 0.04157400131225586 seconds\n",
      "invoking model e2e-3.tar.gz\n",
      "Sentence 1\n",
      "[-0.00097987 -0.00352379 -0.004177   ... -0.00120587 -0.00202981\n",
      " -0.00294534]\n",
      "Sentence 2\n",
      "[-0.00035618 -0.0042098  -0.00419457 ... -0.00180162 -0.00149669\n",
      " -0.0010363 ]\n",
      "Execution time: 0.04192042350769043 seconds\n",
      "invoking model e2e-4.tar.gz\n",
      "Sentence 1\n",
      "[-0.00097987 -0.00352379 -0.004177   ... -0.00120587 -0.00202981\n",
      " -0.00294534]\n",
      "Sentence 2\n",
      "[-0.00035618 -0.0042098  -0.00419457 ... -0.00180162 -0.00149669\n",
      " -0.0010363 ]\n",
      "Execution time: 0.041678428649902344 seconds\n",
      "invoking model e2e-5.tar.gz\n",
      "Sentence 1\n",
      "[-0.00097987 -0.00352379 -0.004177   ... -0.00120587 -0.00202981\n",
      " -0.00294534]\n",
      "Sentence 2\n",
      "[-0.00035618 -0.0042098  -0.00419457 ... -0.00180162 -0.00149669\n",
      " -0.0010363 ]\n",
      "Execution time: 0.04221224784851074 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "for x in range (10):\n",
    "    for counter in [1,2,3,4,5]:   \n",
    "        st = time.time()\n",
    "        target_model=f\"e2e-{counter}.tar.gz\"\n",
    "        print(f\"invoking model {target_model}\")\n",
    "        response = sm_runtime_client.invoke_endpoint(\n",
    "            EndpointName=endpoint_name,\n",
    "            ContentType=\"application/octet-stream\",\n",
    "            Body=request_body,\n",
    "            TargetModel=target_model,\n",
    "        )\n",
    "\n",
    "        header_length_prefix = \"application/vnd.sagemaker-triton.binary+json;json-header-size=\"\n",
    "        header_length_str = response[\"ContentType\"][len(header_length_prefix) :]\n",
    "\n",
    "        # Read response body\n",
    "        result = http_client.InferenceServerClient.parse_response_body(\n",
    "            response[\"Body\"].read(), header_length=int(header_length_str)\n",
    "        )\n",
    "\n",
    "        outputs_data = result.as_numpy(\"SENT_EMBED\")\n",
    "\n",
    "        for idx, output in enumerate(outputs_data):\n",
    "            print(text_inputs[idx])\n",
    "            print(output)\n",
    "        et = time.time()\n",
    "        elapsed_time = et - st\n",
    "        print('Execution time:', elapsed_time, 'seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39fd12bd",
   "metadata": {},
   "source": [
    "# Part 5 - Test SageMaker Endpoint with Java Client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc82ff9",
   "metadata": {},
   "source": [
    "## Build Java App Docker Container"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b30f68",
   "metadata": {},
   "source": [
    "Get credentials first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2e74a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl http://169.254.169.254/latest/meta-data/iam/security-credentials/BaseNotebookInstanceEc2InstanceRole>tmp.json\n",
    "f = open('tmp.json')\n",
    "metadata=json.load(f)\n",
    "os.remove('tmp.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed82f37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./java_client/credentials', 'a') as credentials_file:\n",
    "    credentials_file.write(\"[default]\\n\")\n",
    "    credentials_file.write(f\"aws_access_key_id = {metadata['AccessKeyId']}\\n\")\n",
    "    credentials_file.write(f\"aws_secret_access_key = {metadata['SecretAccessKey']}\\n\")\n",
    "    credentials_file.write(f\"aws_session_token = {metadata['Token']}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc1b0f86",
   "metadata": {},
   "source": [
    "### Build the Docker Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae238c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker build  -t sagemaker-runtime-java-example ./java_client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eae184d",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.remove('./java_client/credentials')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a3e3d40",
   "metadata": {},
   "source": [
    "### Run the Docker Container to invoke the endpoint from Java Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b19e1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker run -e AWS_REGION=us-east-1 -e ENDPOINT_NAME={endpoint_name} sagemaker-runtime-java-example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f51cd97",
   "metadata": {},
   "source": [
    "# Part 6 - Delete the Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea04181e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sm_client.delete_endpoint(EndpointName=endpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec6e25c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.g4dn.xlarge",
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
